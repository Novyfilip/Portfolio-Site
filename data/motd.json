[
    "Overfitting is when your model memorizes the training data instead of learning from it. Like a student who aces the textbook quiz but fails real life.",
    "The F1 score is the harmonic mean of precision and recall — perfect for imbalanced data where accuracy lies.",
    "QDA allows each class to have its own covariance matrix. LDA assumes they all share one. QDA is more flexible, but can overfit with little data.",
    "ROC-AUC doesn’t care about thresholds. It measures how well a model ranks positive cases above negatives.",
    "Stratified sampling ensures each fold or sample respects the original class distribution. It’s fairness in experimentation.",
    "A model is only as good as your understanding of the problem. The best code can’t fix the wrong question.",
    "K-fold cross-validation reduces variance in performance estimates — think of it as a statistical second opinion.",
    "Regularization is what keeps a model humble. L1 promotes sparsity; L2 punishes extreme coefficients.",
    "Correlation is not causation. But causation without correlation is a red flag worth investigating.",
    "Precision is how often you're right when you say 'positive'. Recall is how often you catch all positives.",
    "Bayes’ Theorem teaches us to update beliefs when new evidence arrives. It’s not just math — it’s wisdom.",
    "A confusion matrix reveals what your accuracy hides.",
    "Missing data is never just a nuisance — it’s a story your dataset refuses to tell.",
    "The bias-variance tradeoff is the central dilemma in machine learning: simplify too much, or fit too closely?",
    "Naive Bayes is simple, fast, and surprisingly strong when independence isn’t fatal.",
    "Dimensionality reduction like PCA helps you see the forest, not just the trees.",
    "Hyperparameter tuning is less about brute force, more about knowing what matters.",
    "Accuracy is a blunt tool. F1 score, AUC, and log-loss are your scalpels.",
    "In modeling, elegance is not adding features — it's removing the unnecessary.",
    "Data leakage is when your model cheats without knowing it. Don't let the test set whisper answers."
  ]
  